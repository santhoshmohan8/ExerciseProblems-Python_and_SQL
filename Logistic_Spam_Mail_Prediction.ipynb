{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi2lKVPdRknBuMWGhMsCSO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santhoshmohan8/MachineLearning/blob/main/Logistic_Spam_Mail_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read mail data and check if any NaN and replace any missing values"
      ],
      "metadata": {
        "id": "7U8sMsP7PcpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import data_table\n",
        "from vega_datasets import data\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "spam_data = pd.read_csv(\"mail_data.csv\")\n",
        "spam_data.head()\n",
        "\n",
        "spam_data.isna().sum()\n",
        "print(spam_data.shape,\"\\n\\n\\n\")\n",
        "spam_data.info()\n",
        "print(spam_data.describe(),\"\\n\\n\")\n",
        "spam_data = spam_data.where((pd.notnull(spam_data)),'') # replace NaN values if any\n",
        "print(\"Event rate for target : \\n\",spam_data.Category.value_counts()/spam_data.shape[0]*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0kSzdIwFXR2",
        "outputId": "bf6d9a06-5742-4829-bc32-8ea126693754"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 2) \n",
            "\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Category  5572 non-null   object\n",
            " 1   Message   5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "       Category                 Message\n",
            "count      5572                    5572\n",
            "unique        2                    5157\n",
            "top         ham  Sorry, I'll call later\n",
            "freq       4825                      30 \n",
            "\n",
            "\n",
            "Event rate for target : \n",
            " ham     86.593683\n",
            "spam    13.406317\n",
            "Name: Category, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target variable is categorical, so converting them using Label Encoder\n",
        "\n",
        "*inverse_transform - Checking what is the encoded value for each categories*"
      ],
      "metadata": {
        "id": "5u-isyYIPkAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "target_encoded = encoder.fit_transform(spam_data['Category'])\n",
        "\n",
        "spam_data = pd.concat([spam_data,pd.Series(target_encoded)], axis=1).drop(columns=['Category']).rename(columns={0:'Category'})\n",
        "spam_data.head()\n",
        "\n",
        "target_decoded = encoder.inverse_transform(target_encoded)\n",
        "print(pd.DataFrame(np.vstack((target_decoded,target_encoded)).T).groupby([0,1]).nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS_V3jGRI0tr",
        "outputId": "e8898697-ca78-4ec2-b365-9df8389605a3"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: [(ham, 0), (spam, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test split & TFIDF vectorizer for text features"
      ],
      "metadata": {
        "id": "Z7kdS86KR-Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = spam_data['Message']\n",
        "y = spam_data['Category']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=3)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vector = TfidfVectorizer(stop_words='english',min_df = 1,lowercase = True)\n",
        "\n",
        "x_train_feature = vector.fit_transform(x_train)\n",
        "x_train_feature.shape\n",
        "x_test_feature = vector.transform(x_test)\n",
        "x_test_feature.shape\n",
        "\n",
        "y_train = y_train.astype('int')\n",
        "y_test = y_test.astype('int')"
      ],
      "metadata": {
        "id": "M4z_4l8iMr4u"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model performance metrics - Function"
      ],
      "metadata": {
        "id": "xXTdzXbJbH0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "def model_performance(y_test,y_test_predict):\n",
        "  print(\"\\n\\nConfusion matrix :\\n\",metrics.confusion_matrix(y_test,y_test_predict))\n",
        "  print(\"\\n\\nClassification report :\\n\",metrics.classification_report(y_test,y_test_predict))\n",
        "  print(\"\\nAccuracy score :\",metrics.accuracy_score(y_test,y_test_predict))\n",
        "  print(\"MAPE :\",1-metrics.accuracy_score(y_test,y_test_predict))\n",
        "  print(\"Hamming loss :\",metrics.hamming_loss(y_test,y_test_predict)) # fraction of labels incorrectly predicted\n",
        "  print(\"Jaccard score :\",metrics.jaccard_score(y_test,y_test_predict)) # Jaccard score - not a good metric for imbalanced dataset\n",
        "  print(\"Log loss :\",metrics.log_loss(y_test,y_test_predict)) # log loss or cross entropy loss"
      ],
      "metadata": {
        "id": "dG5oUm2YbIJF"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Predictions"
      ],
      "metadata": {
        "id": "JOx-lWR6Se2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "model = DummyClassifier(strategy='uniform').fit(x_train_feature,y_train)\n",
        "y_train_predict = model.predict(x_train_feature)\n",
        "y_test_predict = model.predict(x_test_feature)\n",
        "model_performance(y_test,y_test_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mullO-GSfMW",
        "outputId": "f8e7e5c0-d0ce-4519-f8f2-3bc4de70e604"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix :\n",
            " [[489 471]\n",
            " [ 81  74]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.51      0.64       960\n",
            "           1       0.14      0.48      0.21       155\n",
            "\n",
            "    accuracy                           0.50      1115\n",
            "   macro avg       0.50      0.49      0.43      1115\n",
            "weighted avg       0.76      0.50      0.58      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.5049327354260089\n",
            "MAPE : 0.4950672645739911\n",
            "Hamming loss : 0.49506726457399103\n",
            "Jaccard score : 0.1182108626198083\n",
            "Log loss : 17.84403288860329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic model with Hyperparameter tuning"
      ],
      "metadata": {
        "id": "7ph4D36rSjDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_list = [\n",
        "    LogisticRegression(),\n",
        "    LogisticRegression(C=1, solver='newton-cg', penalty='l2', max_iter=100),\n",
        "    LogisticRegression(C=1, solver='lbfgs', penalty='l2', max_iter=100),\n",
        "    LogisticRegression(C=1, solver='sag', penalty='l2', max_iter=100),\n",
        "    LogisticRegression(C=1, solver='saga', penalty='l2', max_iter=100)\n",
        "]\n",
        "\n",
        "for model in model_list:\n",
        "  model.fit(x_train_feature,y_train)\n",
        "  y_train_predict = model.predict(x_train_feature)\n",
        "  y_test_predict = model.predict(x_test_feature)\n",
        "  model_performance(y_test,y_test_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A2WU9haSjVk",
        "outputId": "912a2823-a2e1-44d2-b51d-6e2699280d0e"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "MAPE : 0.03408071748878927\n",
            "Hamming loss : 0.034080717488789235\n",
            "Jaccard score : 0.7548387096774194\n",
            "Log loss : 1.2283935684183427\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "MAPE : 0.03408071748878927\n",
            "Hamming loss : 0.034080717488789235\n",
            "Jaccard score : 0.7548387096774194\n",
            "Log loss : 1.2283935684183427\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "MAPE : 0.03408071748878927\n",
            "Hamming loss : 0.034080717488789235\n",
            "Jaccard score : 0.7548387096774194\n",
            "Log loss : 1.2283935684183427\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "MAPE : 0.03408071748878927\n",
            "Hamming loss : 0.034080717488789235\n",
            "Jaccard score : 0.7548387096774194\n",
            "Log loss : 1.2283935684183427\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "MAPE : 0.03408071748878927\n",
            "Hamming loss : 0.034080717488789235\n",
            "Jaccard score : 0.7548387096774194\n",
            "Log loss : 1.2283935684183427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter tuning with Grid Search CV"
      ],
      "metadata": {
        "id": "qw7xipsMjIeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "model_cv = {'C':[0.1,1,10],\n",
        "              'solver':['newton-cg','lbfgs','sag','saga'],\n",
        "              'penalty':['l2'],\n",
        "              'max_iter':[100]}\n",
        "\n",
        "model_GSCV = GridSearchCV(estimator=model,param_grid = model_cv,cv=3).fit(x_train_feature,y_train)\n",
        "print(model_GSCV.best_params_)\n",
        "print(model_GSCV.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQdUGfkDdZXL",
        "outputId": "7f3929fb-c003-40ee-fc34-8da293137333"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.9697105645961636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using best parameters to build a model"
      ],
      "metadata": {
        "id": "4f5HZDOBjMLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(**model_GSCV.best_params_).fit(x_train_feature,y_train)\n",
        "y_train_predict = model.predict(x_train_feature)\n",
        "y_test_predict = model.predict(x_test_feature)\n",
        "model_performance(y_test,y_test_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcH_TCyNgvM2",
        "outputId": "7a465823-a86a-4214-94fb-7701f0817b50"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[959   1]\n",
            " [ 19 136]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       960\n",
            "           1       0.99      0.88      0.93       155\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.94      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9820627802690582\n",
            "MAPE : 0.017937219730941756\n",
            "Hamming loss : 0.017937219730941704\n",
            "Jaccard score : 0.8717948717948718\n",
            "Log loss : 0.6465229307464961\n"
          ]
        }
      ]
    }
  ]
}