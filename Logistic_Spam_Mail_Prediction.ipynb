{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santhoshmohan8/MachineLearning/blob/main/Logistic_Spam_Mail_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U8sMsP7PcpP"
      },
      "source": [
        "Problem Objective :\n",
        "\n",
        "Build a classification model using logistic regression algorithm. Initially a baseline model is build, and Basic logistic regression model is built and a hyperparameter tuned logistic model is build.\n",
        "Different evaluation metrics like confusion matrix, accuracy, precision are chosen to evaluate the performance of the model.\n",
        "AUC-ROC and AUC-PR plots are compared to see any significant performance insight across plots.\n",
        "\n",
        "Spam mail prediction dataset is choosen for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0kSzdIwFXR2",
        "outputId": "bf6d9a06-5742-4829-bc32-8ea126693754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5572, 2) \n",
            "\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Category  5572 non-null   object\n",
            " 1   Message   5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "       Category                 Message\n",
            "count      5572                    5572\n",
            "unique        2                    5157\n",
            "top         ham  Sorry, I'll call later\n",
            "freq       4825                      30 \n",
            "\n",
            "\n",
            "Event rate for target : \n",
            " Category\n",
            "ham     86.593683\n",
            "spam    13.406317\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "spam_data = pd.read_csv(\"mail_data.csv\")\n",
        "spam_data.head()\n",
        "\n",
        "spam_data.isna().sum()\n",
        "print(spam_data.shape,\"\\n\\n\\n\")\n",
        "spam_data.info()\n",
        "print(spam_data.describe(),\"\\n\\n\")\n",
        "spam_data = spam_data.where((pd.notnull(spam_data)),'') # replace NaN values if any\n",
        "print(\"Event rate for target : \\n\",spam_data.Category.value_counts()/spam_data.shape[0]*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u-isyYIPkAg"
      },
      "source": [
        "Target variable is categorical, so converting them using Label Encoder\n",
        "\n",
        "*inverse_transform - Checking what is the encoded value for each categories*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS_V3jGRI0tr",
        "outputId": "e8898697-ca78-4ec2-b365-9df8389605a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: [(ham, 0), (spam, 1)]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "target_encoded = encoder.fit_transform(spam_data['Category'])\n",
        "\n",
        "spam_data = pd.concat([spam_data,pd.Series(target_encoded)], axis=1).drop(columns=['Category']).rename(columns={0:'Category'})\n",
        "spam_data.head()\n",
        "\n",
        "target_decoded = encoder.inverse_transform(target_encoded)\n",
        "print(pd.DataFrame(np.vstack((target_decoded,target_encoded)).T).groupby([0,1]).nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7kdS86KR-Ad"
      },
      "source": [
        "Train test split & TFIDF vectorizer for text features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M4z_4l8iMr4u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = spam_data['Message']\n",
        "y = spam_data['Category']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=3)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vector = TfidfVectorizer(stop_words='english',min_df = 1,lowercase = True)\n",
        "\n",
        "x_train_feature = vector.fit_transform(x_train)\n",
        "x_train_feature.shape\n",
        "x_test_feature = vector.transform(x_test)\n",
        "x_test_feature.shape\n",
        "\n",
        "y_train = y_train.astype('int')\n",
        "y_test = y_test.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXTdzXbJbH0Q"
      },
      "source": [
        "Model performance metrics - Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dG5oUm2YbIJF"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "def model_performance(y_test,y_test_predict):\n",
        "  cm=metrics.confusion_matrix(y_test,y_test_predict)\n",
        "  precision, recall, thresholds = metrics.precision_recall_curve(y_test,y_test_predict)\n",
        "  print(\"\\n\\nConfusion matrix :\\n\",cm)\n",
        "  print(\"\\n\\nClassification report :\\n\",metrics.classification_report(y_test,y_test_predict))\n",
        "  print(\"\\nAccuracy score :\",metrics.accuracy_score(y_test,y_test_predict))\n",
        "  print(\"\\nAUC-ROC Value :\",metrics.roc_auc_score(y_test,y_test_predict))\n",
        "  print(\"\\nAUC-PR Value\",metrics.auc(recall, precision))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOx-lWR6Se2l"
      },
      "source": [
        "Baseline Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mullO-GSfMW",
        "outputId": "f8e7e5c0-d0ce-4519-f8f2-3bc4de70e604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[506 454]\n",
            " [ 76  79]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.53      0.66       960\n",
            "           1       0.15      0.51      0.23       155\n",
            "\n",
            "    accuracy                           0.52      1115\n",
            "   macro avg       0.51      0.52      0.44      1115\n",
            "weighted avg       0.77      0.52      0.60      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.5246636771300448\n",
            "\n",
            "AUC-ROC Value : 0.5183803763440861\n",
            "\n",
            "AUC-PR Value 0.36302824517746557\n"
          ]
        }
      ],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "model = DummyClassifier(strategy='uniform').fit(x_train_feature,y_train)\n",
        "y_train_predict = model.predict(x_train_feature)\n",
        "y_test_predict = model.predict(x_test_feature)\n",
        "model_performance(y_test,y_test_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ph4D36rSjDE"
      },
      "source": [
        "Logistic model with Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A2WU9haSjVk",
        "outputId": "912a2823-a2e1-44d2-b51d-6e2699280d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "\n",
            "AUC-ROC Value : 0.8774193548387097\n",
            "\n",
            "AUC-PR Value 0.8944597135831043\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "\n",
            "AUC-ROC Value : 0.8774193548387097\n",
            "\n",
            "AUC-PR Value 0.8944597135831043\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "\n",
            "AUC-ROC Value : 0.8774193548387097\n",
            "\n",
            "AUC-PR Value 0.8944597135831043\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "\n",
            "AUC-ROC Value : 0.8774193548387097\n",
            "\n",
            "AUC-PR Value 0.8944597135831043\n",
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[960   0]\n",
            " [ 38 117]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       960\n",
            "           1       1.00      0.75      0.86       155\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9659192825112107\n",
            "\n",
            "AUC-ROC Value : 0.8774193548387097\n",
            "\n",
            "AUC-PR Value 0.8944597135831043\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_list = [\n",
        "    LogisticRegression(),\n",
        "    LogisticRegression(C=1, solver='newton-cg', penalty='l2', max_iter=100),\n",
        "    LogisticRegression(C=1, solver='lbfgs', penalty='l2', max_iter=100),\n",
        "    LogisticRegression(C=1, solver='sag', penalty='l2', max_iter=100),\n",
        "    LogisticRegression(C=1, solver='saga', penalty='l2', max_iter=100)\n",
        "]\n",
        "\n",
        "for model in model_list:\n",
        "  model.fit(x_train_feature,y_train)\n",
        "  y_train_predict = model.predict(x_train_feature)\n",
        "  y_test_predict = model.predict(x_test_feature)\n",
        "  model_performance(y_test,y_test_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw7xipsMjIeA"
      },
      "source": [
        "Parameter tuning with Grid Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQdUGfkDdZXL",
        "outputId": "7f3929fb-c003-40ee-fc34-8da293137333"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/priya/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/Users/priya/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/Users/priya/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.9697105645961636\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "model_cv = {'C':[0.1,1,10],\n",
        "              'solver':['newton-cg','lbfgs','sag','saga'],\n",
        "              'penalty':['l2'],\n",
        "              'max_iter':[100]}\n",
        "\n",
        "model_GSCV = GridSearchCV(estimator=model,param_grid = model_cv,cv=3).fit(x_train_feature,y_train)\n",
        "print(model_GSCV.best_params_)\n",
        "print(model_GSCV.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f5HZDOBjMLF"
      },
      "source": [
        "Using best parameters to build a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcH_TCyNgvM2",
        "outputId": "7a465823-a86a-4214-94fb-7701f0817b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Confusion matrix :\n",
            " [[959   1]\n",
            " [ 19 136]]\n",
            "\n",
            "\n",
            "Classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       960\n",
            "           1       0.99      0.88      0.93       155\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.94      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "\n",
            "Accuracy score : 0.9820627802690582\n",
            "\n",
            "AUC-ROC Value : 0.9381888440860215\n",
            "\n",
            "AUC-PR Value 0.9435802217550558\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression(**model_GSCV.best_params_).fit(x_train_feature,y_train)\n",
        "y_train_predict = model.predict(x_train_feature)\n",
        "y_test_predict = model.predict(x_test_feature)\n",
        "model_performance(y_test,y_test_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot AUC-ROC curve and AUC-PR Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'plot_precision_recall_curve' from 'sklearn.metrics' (/Users/priya/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/Users/priya/MachineLearning/Logistic_Spam_Mail_Prediction.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/priya/MachineLearning/Logistic_Spam_Mail_Prediction.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_precision_recall_curve\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/priya/MachineLearning/Logistic_Spam_Mail_Prediction.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plot_precision_recall_curve(model,x_test,y_test)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_precision_recall_curve' from 'sklearn.metrics' (/Users/priya/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/__init__.py)"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "plot_precision_recall_curve(model,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOi2lKVPdRknBuMWGhMsCSO",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
